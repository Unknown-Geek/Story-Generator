{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZslXpMigw5rU"
   },
   "source": [
    "https://colab.research.google.com/drive/1hc8G2WY_4P_0Tri-lZ0HmVDdX6MKy5LV#scrollTo=rcFWDyYIt733"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QRlSOXoxZD7L"
   },
   "outputs": [],
   "source": [
    "# Remove all potentially conflicting packages\n",
    "!pip uninstall -y transformers diffusers huggingface-hub sentence-transformers accelerate peft\n",
    "\n",
    "!pip install -q torch torchvision\n",
    "!pip install -q huggingface-hub==0.19.4\n",
    "!pip install -q accelerate==0.25.0\n",
    "!pip install -q transformers==4.36.2\n",
    "!pip install -q diffusers==0.24.0\n",
    "!pip install -q safetensors==0.4.1\n",
    "!pip install -q peft==0.7.1\n",
    "!pip install -q flask-cors pyngrok flask\n",
    "\n",
    "from google.colab import userdata\n",
    "NGROK_TOKEN = userdata.get('NGROK_AUTH_TOKEN')\n",
    "\n",
    "# Configure ngrok\n",
    "!ngrok authtoken $NGROK_TOKEN\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "unique_id_here"
   },
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from pyngrok import ngrok\n",
    "import torch\n",
    "from diffusers import DiffusionPipeline\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "!pkill ngrok\n",
    "\n",
    "def initialize_pipeline():\n",
    "    try:\n",
    "        pipe = DiffusionPipeline.from_pretrained(\n",
    "        \"stabilityai/sdxl-turbo\",\n",
    "        torch_dtype=torch.float16,\n",
    "        variant=\"fp16\",\n",
    "        )\n",
    "        if torch.cuda.is_available():\n",
    "            pipe = pipe.to(\"cuda\")\n",
    "        return pipe\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing pipeline: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# Initialize the pipeline\n",
    "pipe = initialize_pipeline()\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health_check():\n",
    "    return jsonify({\n",
    "        'status': 'healthy',\n",
    "        'gpu_available': torch.cuda.is_available(),\n",
    "        'torch_version': torch.__version__,\n",
    "        'cuda_version': torch.version.cuda if torch.cuda.is_available() else None\n",
    "    })\n",
    "\n",
    "@app.route('/generate_frame', methods=['POST'])\n",
    "def generate_frame():\n",
    "    if pipe is None:\n",
    "        return jsonify({'success': False, 'error': 'Pipeline not initialized'}), 500\n",
    "\n",
    "    try:\n",
    "        data = request.json\n",
    "        prompt = data.get('prompt', '')\n",
    "\n",
    "        if not prompt:\n",
    "            return jsonify({'success': False, 'error': 'No prompt provided'}), 400\n",
    "\n",
    "        # Optional parameters with defaults\n",
    "        height = data.get('height', 512)\n",
    "        width = data.get('width', 512)\n",
    "        num_inference_steps = data.get('num_inference_steps', 1)\n",
    "        guidance_scale = data.get('guidance_scale', 0.0)\n",
    "\n",
    "        # Generate image\n",
    "        image = pipe(\n",
    "            prompt=prompt,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            height=height,\n",
    "            width=width\n",
    "        ).images[0]\n",
    "\n",
    "        # Convert to base64\n",
    "        buffered = io.BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\", quality=95)\n",
    "        img_str = base64.b64encode(buffered.getvalue()).decode()\n",
    "\n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'image': f'data:image/jpeg;base64,{img_str}'\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({'success': False, 'error': str(e)}), 500\n",
    "\n",
    "# Setup ngrok and start server\n",
    "try:\n",
    "    public_url = ngrok.connect(5000)\n",
    "    print(f'\\nServer running at: {public_url}')\n",
    "    print(f'Frame generation endpoint: {public_url}/generate_frame')\n",
    "    print(f'Health check endpoint: {public_url}/health\\n')\n",
    "\n",
    "    # Start Flask server\n",
    "    app.run(port=5000)\n",
    "except Exception as e:\n",
    "    print(f\"Error starting server: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rcFWDyYIt733"
   },
   "outputs": [],
   "source": [
    "# Installation\n",
    "\"\"\"\n",
    "pip install flask flask-cors pyngrok replicate\n",
    "\"\"\"\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from pyngrok import ngrok\n",
    "import replicate\n",
    "import base64\n",
    "import requests\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health_check():\n",
    "    return jsonify({'status': 'healthy'})\n",
    "\n",
    "@app.route('/generate_frames', methods=['POST'])\n",
    "def generate_frames():\n",
    "    try:\n",
    "        data = request.json\n",
    "        prompt = data.get('prompt', '')\n",
    "\n",
    "        if not prompt:\n",
    "            return jsonify({'success': False, 'error': 'No prompt provided'}), 400\n",
    "\n",
    "        # Using AnimateDiff through Replicate API\n",
    "        output = replicate.run(\n",
    "            \"lucataco/animate-diff:1531004ee4c98894ab11f8a4ce6206099e732c1da15121987a8eef54828f0663\",\n",
    "            input={\n",
    "                \"prompt\": prompt,\n",
    "                \"negative_prompt\": \"blurry, bad quality, distorted\",\n",
    "                \"num_frames\": 16,  # Number of frames to generate\n",
    "                \"fps\": 8,  # Frames per second\n",
    "                \"num_inference_steps\": 20,\n",
    "                \"guidance_scale\": 7.5,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Output will be a URL to the generated animation\n",
    "\n",
    "        # Download and convert frames if needed\n",
    "        if isinstance(output, list) and len(output) > 0:\n",
    "            animation_url = output[0]\n",
    "            response = requests.get(animation_url)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                # Convert to base64 for sending back\n",
    "                img_str = base64.b64encode(response.content).decode()\n",
    "\n",
    "                return jsonify({\n",
    "                    'success': True,\n",
    "                    'animation': f'data:image/gif;base64,{img_str}',\n",
    "                    'url': animation_url\n",
    "                })\n",
    "\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': 'Failed to generate animation'\n",
    "        }), 500\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({'success': False, 'error': str(e)}), 500\n",
    "\n",
    "# Setup test route to generate a sample animation\n",
    "@app.route('/test', methods=['GET'])\n",
    "def test_generation():\n",
    "    test_prompt = \"A cute cat walking in a garden, Studio Ghibli style\"\n",
    "    return generate_frames(), {\n",
    "        'prompt': test_prompt\n",
    "    }\n",
    "\n",
    "def start_server():\n",
    "    try:\n",
    "        # Setup ngrok\n",
    "        public_url = ngrok.connect(5000)\n",
    "        print(f'\\nServer running at: {public_url}')\n",
    "        print(f'Frame generation endpoint: {public_url}/generate_frames')\n",
    "        print(f'Test endpoint: {public_url}/test')\n",
    "        print(f'Health check endpoint: {public_url}/health\\n')\n",
    "\n",
    "        # Start Flask server\n",
    "        app.run(port=5000)\n",
    "    except Exception as e:\n",
    "        print(f\"Error starting server: {str(e)}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_server()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
