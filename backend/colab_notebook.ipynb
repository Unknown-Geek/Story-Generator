{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Story Generator Local Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a48ca7b",
   "metadata": {},
   "source": [
    "[Google Notebook](https://colab.research.google.com/drive/1uNygzDR4hISwLOgmDS31hRHfr6KAF7Ib?usp=sharing#scrollTo=unique_id_here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies installed successfully!\n"
     ]
    }
   ],
   "source": [
    "%pip install -q transformers==4.35.2 accelerate bitsandbytes==0.41.1 huggingface_hub google-generativeai==0.3.1\n",
    "%pip install -q Flask==2.3.2 Pillow==9.5.0 requests==2.30.0 flask-ngrok Flask-CORS==3.0.10 pyngrok\n",
    "%pip install Flask-Cors\n",
    "import os\n",
    "\n",
    "# Use environment variables\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "login(os.getenv('HUGGINGFACE_API_KEY'))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=False)\n",
    "\n",
    "print(\"Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b65679",
   "metadata": {
    "id": "server_cell"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t=2024-11-15T16:32:03+0530 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=C:\\\\Users\\\\Shravan\\\\AppData\\\\Local/ngrok/ngrok.yml legacy_path=C:\\\\Users\\\\Shravan\\\\.ngrok2\\\\ngrok.yml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting server...\n",
      "\n",
      "Ngrok tunnel established at: NgrokTunnel: \"https://c271-2409-40f3-101b-f886-7095-d6fa-4e8b-6f3e.ngrok-free.app\" -> \"http://localhost:5000\"\n",
      "Story generation endpoint: NgrokTunnel: \"https://c271-2409-40f3-101b-f886-7095-d6fa-4e8b-6f3e.ngrok-free.app\" -> \"http://localhost:5000\"/generate_story\n",
      "\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Image mode: RGB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Nov/2024 16:34:37] \"POST /generate_story HTTP/1.1\" 400 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Image processing error: 404 Gemini 1.0 Pro Vision has been deprecated on July 12, 2024. Consider switching to different model, for example gemini-1.5-flash.\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from pyngrok import ngrok\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# Configure Gemini API\n",
    "genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))\n",
    "generation_config = {\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.8,\n",
    "    \"top_k\": 40,\n",
    "    \"max_output_tokens\": 8192,\n",
    "}\n",
    "\n",
    "# Use gemini-1.5-pro for vision\n",
    "vision_model = genai.GenerativeModel('gemini-1.5-pro', generation_config=generation_config)\n",
    "\n",
    "# Use gemini-pro for story generation\n",
    "story_model = genai.GenerativeModel('gemini-pro', generation_config=generation_config)\n",
    "\n",
    "# Configure ngrok with auth token from environment\n",
    "ngrok.set_auth_token(os.getenv('NGROK_AUTH_TOKEN'))\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "@app.route('/generate_story', methods=['POST'])\n",
    "def generate_story():\n",
    "    try:\n",
    "        data = request.json\n",
    "        if not data:\n",
    "            print(\"DEBUG: No data received in request\")\n",
    "            return jsonify({'success': False, 'error': 'No data received'}), 400\n",
    "\n",
    "        image_data = data.get('image', '')\n",
    "        genre = data.get('genre', 'fantasy').lower()\n",
    "        word_count = data.get('length', 200)\n",
    "\n",
    "        if 'base64,' in image_data:\n",
    "            image_data = image_data.split('base64,')[1]\n",
    "\n",
    "        if not image_data:\n",
    "            return jsonify({'success': False, 'error': 'No image data provided'}), 400\n",
    "\n",
    "        try:\n",
    "            # Process image\n",
    "            image_bytes = base64.b64decode(image_data)\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "            print(f\"DEBUG: Image mode: {image.mode}\")\n",
    "                \n",
    "            # Convert to RGB if needed\n",
    "            if image.mode in ('RGBA', 'LA'):\n",
    "                background = Image.new('RGB', image.size, (255, 255, 255))\n",
    "                background.paste(image, mask=image.split()[-1])\n",
    "                image = background\n",
    "            elif image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "                \n",
    "            # Create model for image analysis\n",
    "            vision_model = genai.GenerativeModel('gemini-1.5-pro-vision')\n",
    "            \n",
    "            # Generate image prompt\n",
    "            image_prompt = \"Describe what you see in this image concisely.\"\n",
    "            image_response = vision_model.generate_content([image_prompt, image])\n",
    "            image_description = image_response.text\n",
    "            print(f\"DEBUG: Image description: {image_description}\")\n",
    "\n",
    "        except Exception as img_error:\n",
    "            print(f\"DEBUG: Image processing error: {str(img_error)}\")\n",
    "            return jsonify({'success': False, 'error': f'Image processing error: {str(img_error)}'}), 400\n",
    "\n",
    "        # Craft prompt\n",
    "        prompt = f\"\"\"Write a {genre} story appropriate for all ages. Base it on this scene: {image_description}\n",
    "        Requirements:\n",
    "        - Length: approximately {word_count} words\n",
    "        - Age-appropriate content\n",
    "        - Clear narrative structure\n",
    "        - Engaging and descriptive language\n",
    "        - Positive message or moral\"\"\"\n",
    "\n",
    "        print(f\"DEBUG: Generated prompt: {prompt}\")\n",
    "\n",
    "        # Generate story\n",
    "        response = model.generate_content(prompt)\n",
    "\n",
    "        if response.text:\n",
    "            return jsonify({'success': True, 'story': response.text})\n",
    "        else:\n",
    "            return jsonify({\n",
    "                'success': False,\n",
    "                'error': 'Story generation failed. Please try again.'\n",
    "            }), 500\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"DEBUG: Server error: {str(e)}\")\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': f'Server error: {str(e)}'\n",
    "        }), 500\n",
    "\n",
    "print(\"Starting server...\")\n",
    "try:\n",
    "    # Start ngrok tunnel\n",
    "    public_url = ngrok.connect(5000)\n",
    "    print(f'\\nNgrok tunnel established at: {public_url}')\n",
    "    print(f'Story generation endpoint: {public_url}/generate_story\\n')\n",
    "    \n",
    "    # Start Flask app\n",
    "    app.run(port=5000)\n",
    "except Exception as e:\n",
    "    print(f\"Error starting server: {str(e)}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
