{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Link\n",
    "https://colab.research.google.com/drive/1uNygzDR4hISwLOgmDS31hRHfr6KAF7Ib?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "clear_output(wait=False)\n",
    "\n",
    "!wget https://raw.githubusercontent.com/Unknown-Geek/Story-Generator/main/requirements.txt\n",
    "!wget https://raw.githubusercontent.com/Unknown-Geek/Story-Generator/main/setup.py\n",
    "!python setup.py\n",
    "\n",
    "clear_output(wait=False)\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# Configure ngrok\n",
    "from pyngrok import ngrok\n",
    "ngrok.set_auth_token('2oHUyMyGNJuD34GO6NdGJd8KAxd_3TyYzUGLMA9DvgUopNRw3')\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "def load_models():\n",
    "    # Initialize device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Load image captioning model\n",
    "    image_captioner = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-base\")\n",
    "    \n",
    "    # Load story generation model\n",
    "    model_name = \"gpt2\"\n",
    "    story_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    story_model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "    \n",
    "    return image_captioner, story_tokenizer, story_model, device\n",
    "\n",
    "@app.route('/generate_story', methods=['POST'])\n",
    "def generate_story():\n",
    "    try:\n",
    "        data = request.json\n",
    "        image_data = data['image'].split(',')[1]  # Remove the data:image/jpeg;base64 prefix\n",
    "        genre = data['genre']\n",
    "        \n",
    "        # Decode base64 image\n",
    "        image_bytes = base64.b64decode(image_data)\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "        \n",
    "        # Generate image caption\n",
    "        caption = image_captioner(image)[0]['generated_text']\n",
    "        \n",
    "        # Create prompt for story generation\n",
    "        prompt = f\"Write a {genre.lower()} story about: {caption}\\n\\nStory:\"\n",
    "        \n",
    "        # Generate story\n",
    "        inputs = story_tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "        output_sequences = story_model.generate(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            max_length=200,\n",
    "            temperature=0.8,\n",
    "            top_k=50,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.2,\n",
    "            do_sample=True,\n",
    "            num_return_sequences=1\n",
    "        )\n",
    "        \n",
    "        story = story_tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'story': story.replace(prompt, '').strip()\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=False)\n",
    "\n",
    "def start_server():\n",
    "    try:\n",
    "        ngrok.kill()\n",
    "        public_url = ngrok.connect(5000)\n",
    "        clear_output(wait=False)\n",
    "        print(f'Server running at: {public_url}')\n",
    "        \n",
    "        from url_store import save_url\n",
    "        save_url(str(public_url))\n",
    "        app.run(port=5000)\n",
    "    except Exception as e:\n",
    "        print(f'Error starting server: {str(e)}')\n",
    "        ngrok.kill()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Loading AI models...\")\n",
    "    try:\n",
    "        image_captioner, story_tokenizer, story_model, device = load_models()\n",
    "        clear_output(wait=False)\n",
    "        print(\"Models loaded successfully!\")\n",
    "        print(\"Starting the server...\")\n",
    "        start_server()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        ngrok.kill()\n",
    "        \n",
    "clear_output(wait=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
