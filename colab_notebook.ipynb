{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Link\n",
    "https://colab.research.google.com/drive/1uNygzDR4hISwLOgmDS31hRHfr6KAF7Ib?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "clear_output(wait=False)\n",
    "\n",
    "!pip install Flask==2.3.2 Pillow==9.5.0 requests==2.30.0 flask-ngrok Flask-CORS==3.0.10 pyngrok transformers torch torchvision\n",
    "\n",
    "clear_output(wait=False)\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# Configure ngrok\n",
    "ngrok.set_auth_token('2oHUyMyGNJuD34GO6NdGJd8KAxd_3TyYzUGLMA9DvgUopNRw3')\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# Global variables for models\n",
    "image_captioner = None\n",
    "story_tokenizer = None\n",
    "story_model = None\n",
    "device = None\n",
    "\n",
    "def load_models():\n",
    "    global image_captioner, story_tokenizer, story_model, device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    image_captioner = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-base\", device=device)\n",
    "    model_name = \"gpt2\"\n",
    "    story_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    story_model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "@app.route('/generate_story', methods=['POST'])\n",
    "def generate_story():\n",
    "    try:\n",
    "        data = request.json\n",
    "        image_data = data['image'].split(',')[1]\n",
    "        genre = data['genre']\n",
    "\n",
    "        # Process image\n",
    "        image_bytes = base64.b64decode(image_data)\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "        # Generate caption\n",
    "        caption = image_captioner(image)[0]['generated_text']\n",
    "\n",
    "        # Generate story\n",
    "        prompt = f\"Write a {genre.lower()} story about: {caption}\\n\\nStory:\"\n",
    "        inputs = story_tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "        output_sequences = story_model.generate(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            max_length=200,\n",
    "            temperature=0.8,\n",
    "            top_k=50,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.2,\n",
    "            do_sample=True,\n",
    "            num_return_sequences=1\n",
    "        )\n",
    "\n",
    "        story = story_tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'story': story.replace(prompt, '').strip()\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Loading AI models...\")\n",
    "    load_models()\n",
    "    print(\"Models loaded successfully!\")\n",
    "    \n",
    "    public_url = ngrok.connect(5000)\n",
    "    api_url = f\"{public_url.public_url}/generate_story\"\n",
    "    print(f'Server running at: {api_url}')\n",
    "    \n",
    "    app.run(port=5000)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
